{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scipy.signal import welch\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(segment):\n",
    "    frequency, power = welch(segment[\"BVP\"], fs=4.0, nperseg=120/8)\n",
    "    max_index = power.argmax()\n",
    "    frequency_max = frequency[max_index]\n",
    "    power_max = power_max = power[max_index]\n",
    "\n",
    "    descriptive_features = segment.describe(percentiles=[0.1, 0.5, 0.9]).values[1:,:].flatten()\n",
    "    correlation_features = segment.corr().values[np.triu_indices(6, 1)]\n",
    "\n",
    "    output_features = np.concatenate([power, [frequency_max, power_max], descriptive_features, correlation_features])\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions(patient_id, model, probability_threshold=0.5):\n",
    "    labels = pd.read_csv(f\"data\\data\\{patient}\\{patient}_labels.csv\")\n",
    "    n_segments = int((labels[\"duration\"][0]-labels[\"duration\"][0]%30000)/30000)\n",
    "    \n",
    "    test_segments = {i: None for i in range(n_segments)}\n",
    "    test_features = {i: None for i in range(n_segments)}\n",
    "    for i in tqdm(range(n_segments)):\n",
    "        try:\n",
    "            test_segments[i] = pd.read_parquet(f\"data/segments/test/{patient_id}/{patient_id}_test_segment_{i}.parquet\")\n",
    "            test_features[i] = get_features(test_segments[i])\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "    prediction_values = model.predict_proba([v for v in test_features.values() if v is not None])\n",
    "    prediction_values = prediction_values[:, 1]\n",
    "\n",
    "    index = [k for k, v in test_segments.items() if v is not None]\n",
    "    predictions = pd.DataFrame(data={\"prediction_probability\":prediction_values}, index=index)\n",
    "    predictions[\"time\"] = (predictions.index+1)*30000\n",
    "    predictions[\"prediction\"] = predictions[\"prediction_probability\"] > probability_threshold\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:02<00:00,  8.93s/it]\n"
     ]
    }
   ],
   "source": [
    "patients = [\"MSEL_00172\", \"MSEL_00501\", \"MSEL_01097\", \"MSEL_01575\", \"MSEL_01808\", \"MSEL_01838\", \"MSEL_01842\"]\n",
    "patient_data = {patient:{\"X\":[], \"y\":[]} for patient in patients}\n",
    "for patient in tqdm(patients):\n",
    "    interictal_segment_files = glob(f\"data/segments/scaled/{patient}/interictal/{patient}_interictal_scaled_segment_*.parquet\")\n",
    "    preictal_segment_files= glob(f\"data/segments/scaled/{patient}/preictal/{patient}_preictal_scaled_segment_*.parquet\")\n",
    "    interictal_segment_files = list(np.random.choice(interictal_segment_files, size=len(preictal_segment_files), replace=False))\n",
    "    for segment_file in interictal_segment_files:\n",
    "        segment = pd.read_parquet(segment_file)\n",
    "        features = get_features(segment)\n",
    "        if any(np.isnan(features)):\n",
    "            continue\n",
    "        patient_data[patient][\"X\"].append(features)\n",
    "        patient_data[patient][\"y\"].append(0)\n",
    "    for segment_file in preictal_segment_files:\n",
    "        segment = pd.read_parquet(segment_file)\n",
    "        features = get_features(segment)\n",
    "        if any(np.isnan(features)):\n",
    "            continue\n",
    "        patient_data[patient][\"X\"].append(features)\n",
    "        patient_data[patient][\"y\"].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_00172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8398/8398 [01:07<00:00, 124.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_00501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10578/10578 [01:12<00:00, 145.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_01097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14050/14050 [01:51<00:00, 126.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_01575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14788/14788 [01:41<00:00, 145.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_01808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10994/10994 [01:27<00:00, 126.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_01838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13635/13635 [01:44<00:00, 130.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient: MSEL_01842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10109/10109 [01:19<00:00, 127.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000, C=0.005)\n",
    "train_accuracy = {}\n",
    "validation_accuracy = {}\n",
    "test_predictions = {}\n",
    "evaluation_metrics = {}\n",
    "for patient in patients:\n",
    "    print(f\"Test patient: {patient}\")\n",
    "    X_test = patient_data[patient][\"X\"]\n",
    "    y_test = patient_data[patient][\"y\"]\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for p in patients:\n",
    "        if p != patient:\n",
    "            X_train.extend(patient_data[p][\"X\"])\n",
    "            y_train.extend(patient_data[p][\"y\"])     \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy[patient] = model.score(X_train, y_train)\n",
    "    validation_accuracy[patient] = model.score(X_test, y_test)\n",
    "\n",
    "    test_predictions[patient] = get_test_predictions(patient, model)\n",
    "    evaluation_metrics[patient] = evaluate(patient, test_predictions[patient], integration_windows=[600000], thresholds=[0.55], timer_duration=3600000, detection_interval=60000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5488621245052683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(validation_accuracy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6204828153830503"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(train_accuracy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSEL_00172': {'600000_0.55': {'S': 0.6,\n",
       "   'TiW': 0.5371694067190851,\n",
       "   'IoC': 0.06877313045065014,\n",
       "   'p': 0.7586683617396658,\n",
       "   'n': 6,\n",
       "   'N': 10}},\n",
       " 'MSEL_00501': {'600000_0.55': {'S': 1.0,\n",
       "   'TiW': 0.5291293213828425,\n",
       "   'IoC': 0.4767812990762996,\n",
       "   'p': 1.0,\n",
       "   'n': 1,\n",
       "   'N': 1}},\n",
       " 'MSEL_01097': {'600000_0.55': {'S': 1.0,\n",
       "   'TiW': 0.8248362289945884,\n",
       "   'IoC': 0.18024874888277154,\n",
       "   'p': 1.0,\n",
       "   'n': 2,\n",
       "   'N': 2}},\n",
       " 'MSEL_01575': {'600000_0.55': {'S': 0.9876543209876543,\n",
       "   'TiW': 0.8045448397132423,\n",
       "   'IoC': 0.1884265922324877,\n",
       "   'p': 4.730228986455627e-05,\n",
       "   'n': 80,\n",
       "   'N': 81}},\n",
       " 'MSEL_01808': {'600000_0.55': {'S': 1.0,\n",
       "   'TiW': 0.9954520647625977,\n",
       "   'IoC': 0.004956187358888142,\n",
       "   'p': 1.0,\n",
       "   'n': 8,\n",
       "   'N': 8}},\n",
       " 'MSEL_01838': {'600000_0.55': {'S': 0.3333333333333333,\n",
       "   'TiW': 0.28874220755408875,\n",
       "   'IoC': 0.04863010402186302,\n",
       "   'p': 1.0,\n",
       "   'n': 1,\n",
       "   'N': 3}},\n",
       " 'MSEL_01842': {'600000_0.55': {'S': 1.0,\n",
       "   'TiW': 0.6657103284527107,\n",
       "   'IoC': 0.3403942842959936,\n",
       "   'p': 0.5509479689707762,\n",
       "   'n': 2,\n",
       "   'N': 2}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'600000_0.55': {'S': 1.0,\n",
       "  'TiW': 0.7452996077370485,\n",
       "  'IoC': 0.27210432628682346,\n",
       "  'p': 0.6038728761943652,\n",
       "  'n': 2,\n",
       "  'N': 2}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(patient, test_predictions[\"MSEL_01575\"], integration_windows=[600000], thresholds=[0.55], timer_duration=1200000, detection_interval=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_values = []\n",
    "for i in range(100):\n",
    "    for x in fake_predictions.values():\n",
    "        x[\"prediction_probability\"] = np.random.uniform(0, 1, len(x[\"prediction_probability\"]))\n",
    "        x[\"prediction\"] = x[\"prediction_probability\"] > 0.55\n",
    "    new_iocs = [list(evaluate(patient, fake_predictions[patient], integration_windows=[600000], thresholds=[0.55], timer_duration=3600000, detection_interval=60000).values())[0][\"IoC\"] for patient in patients]\n",
    "    ioc_values.extend(new_iocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485714285714286"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(ioc_values)>0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     344781000\n",
       "2     402589000\n",
       "3     403088000\n",
       "4     403240000\n",
       "5     403286000\n",
       "        ...    \n",
       "77    411054000\n",
       "78    411457000\n",
       "79    411596000\n",
       "80    411710000\n",
       "81    411848000\n",
       "Name: labels.startTime, Length: 81, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seizure_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = 'MSEL_01575'\n",
    "labels = pd.read_csv(f\"data\\data\\{patient}\\{patient}_labels.csv\")\n",
    "n_segments = int((labels[\"duration\"][0]-labels[\"duration\"][0]%30000)/30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() missing 6 required positional arguments: 'patient_id', 'predictions', 'integration_windows', 'thresholds', 'timer_duration', and 'detection_interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-3f393ad04e6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: evaluate() missing 6 required positional arguments: 'patient_id', 'predictions', 'integration_windows', 'thresholds', 'timer_duration', and 'detection_interval'"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab9f64ede123343d9ad5b28ae676d0ce0e26d6747c3528440fbd05d255310970"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
